# Barcode Reader

## ML Terminology Coaching
When the user uses ML terminology (correctly or incorrectly), briefly correct or affirm their usage BEFORE continuing with the primary response. This helps them learn to speak more precisely about ML concepts. Keep corrections short and constructive.

## Project Structure
- `features.py` — Shared feature extraction module (n-grams, timing, hotkeys, clicks)
- `train.py` — Train model, LOO cross-validation, save to `data/model.joblib`
- `predict.py` — Load saved model, predict on all unlabeled players (10+ games)
- `ingest_replays.py` — Replay ingestion pipeline (to_ingest → replays)
- `cwal.py` — CLI tool for cwal.gg API (matches, scrape, rankings, search, handles)
- `experiments.md` — **MUST UPDATE** after every training iteration

## Directory Layout
```
barcode-reader/
├── features.py              # Shared feature extraction
├── train.py                 # Train model + LOO CV
├── predict.py               # Predict unlabeled players
├── ingest_replays.py        # Ingest to_ingest/ → replays/
├── cwal.py                  # cwal.gg API CLI tool
├── experiments.md           # Experiment log (MUST UPDATE after training)
├── CLAUDE.md                # This file
├── docs/                    # Personal notes / reference docs
├── data/
│   ├── replays.db           # SQLite database (source of truth)
│   ├── model.joblib          # Trained model (regenerated by train.py)
│   ├── predictions.json     # Latest predictions (regenerated by predict.py)
│   ├── players_list.txt     # Player summary (regenerated)
│   ├── replays/             # All .rep files (referenced by DB file_path)
│   ├── to_ingest/           # Landing zone for new replays → run ingest_replays.py
│   ├── scraped_overflow/    # (unused — all replays now ingested fully)
│   ├── plots/               # PNGs from analysis/experiments
│   └── experiments/         # Old experiment result JSONs
```

## Conventions
- **Modern era only (2025+)** — all training, analysis, and queries default to game_date >= 2025-01-01 unless explicitly noted otherwise
- Python venv at `.venv/` — use `.venv/bin/python` to run scripts
- Replay parser: `~/go/bin/screp` (Go binary, use with `-cmds` for commands, `-map` for positions)
- Database: `data/replays.db` (SQLite)
- New replays go to `data/to_ingest/`, get moved to `data/replays/` after ingestion
- With `class_weight="balanced"`, all available replays are used — no need to cap or overflow

## Data Labeling Rules
- This is data for training a classification model. It must be **HIGH FIDELITY**. Never alias or label without 100% confidence that the mapping is correct.
- **NEVER add player_aliases without explicit user confirmation.** Only add the exact aliases the user tells you.
- Don't guess or infer additional aliases from similar names in the database.

## Scraping Rules
- Scrape all available replays for labeled players — more data is better with `class_weight="balanced"`.
- For initial exploration of an unlabeled player, `--limit 50` is fine.

## Database Schema (data/replays.db)
- **replays** — one row per replay file: `id, file_hash, file_path, file_name, source_dir, map_name, game_date, duration_seconds, frames, version, created_at, winner_team`
- **players** — one row per player per replay: `id, replay_id, slot_id, player_name, race, is_human, start_x, start_y, start_direction`
- **player_aliases** — maps in-game names to canonical pro names: `id, canonical_name, alias, confidence, source, aurora_id, valid_from, valid_to`

## Current Model
- **Random Forest**: depth=10, trees=200, StandardScaler, LOO cross-validation
- **Modern era only**: Trains on replays with game_date >= 2025-01-01
- **99.1% accuracy** on 16 modern pros (stale — retrain pending with new players + code changes)
- Model saved to `data/model.joblib`, predictions to `data/predictions.json`
- Race-neutral features: abstract race-specific actions into generic categories (Train/Unit Morph → Prod)
- Consecutive Prod collapse to reduce race-mechanical signal

## Training & Prediction Thresholds
- **Training**: Auto-discovers all labeled players (in `player_aliases`) with 10+ valid modern-era games. No per-player cap — uses `class_weight="balanced"` to handle class imbalance.
- **Prediction**: Runs on all unlabeled players with 10+ modern-era games
- **Filtering**: Single gate in `features.py` — games must be ≥ `MIN_GAME_MINUTES` (4) and ≥ `MIN_COMMANDS` (100)

## Workflow: Adding a New Player
1. Find their cwal.gg alias: `cwal.py search <name>`
2. Scrape replays: `cwal.py scrape <alias> --limit 50`
3. Add alias to DB (only with user confirmation): INSERT INTO player_aliases
4. Ingest: `python ingest_replays.py`
5. Retrain: `python train.py`
6. Update experiments.md with results

## Blind Validation Queue
These are account-confirmed identities (via aurora_id) NOT yet aliased. Re-predict and check accuracy before aliasing.
- `llIIll1ll1lI` = Jaedong (aurora_id 13968871, gateway 11)
- `C9_HyuK9` = likely HyuK (same C9 tag, Zerg, but different account from C9_PSM — confirm via aurora_id or prediction)

## cwal.gg API Notes
- Duration in `player_matches` is in **seconds** (decimal, e.g. 417.396 = 6:57)
- `map_name` field contains BW color codes (control chars) — use `map_file_name` instead
- `battlenet_account` field is on the `players` table, NOT on `rankings_view`
- Default gateway 30 = Korea, 10 = US West, 20 = US East, 45 = Europe
