# Barcode Reader

## ML Terminology Coaching
When the user uses ML terminology (correctly or incorrectly), briefly correct or affirm their usage BEFORE continuing with the primary response. This helps them learn to speak more precisely about ML concepts. Keep corrections short and constructive.

## Project Structure
- `features.py` — Shared feature extraction module (n-grams, timing, hotkeys, clicks)
- `train.py` — Train model, LOO cross-validation, save to `data/model.joblib`
- `predict.py` — Load saved model, predict on all unlabeled players (10+ games)
- `ingest_replays.py` — Replay ingestion pipeline (to_ingest → replays)
- `backfill_aurora_ids.py` — Migration/backfill script for aurora_ids (Tier 1: offline, Tier 2: API)
- `cwal.py` — CLI tool for cwal.gg API (matches, scrape, rankings, search, handles)
- `experiments.md` — **MUST UPDATE** after every training iteration

## Directory Layout
```
barcode-reader/
├── features.py              # Shared feature extraction
├── train.py                 # Train model + LOO CV
├── predict.py               # Predict unlabeled players
├── ingest_replays.py        # Ingest to_ingest/ → replays/
├── backfill_aurora_ids.py   # Aurora_id migration/backfill
├── cwal.py                  # cwal.gg API CLI tool
├── experiments.md           # Experiment log (MUST UPDATE after training)
├── CLAUDE.md                # This file
├── docs/                    # Personal notes / reference docs
├── data/
│   ├── replays.db           # SQLite database (source of truth)
│   ├── model.joblib          # Trained model (regenerated by train.py)
│   ├── predictions.json     # Latest predictions (regenerated by predict.py)
│   ├── players_list.txt     # Player summary (regenerated)
│   ├── replays/             # All .rep files (referenced by DB file_path)
│   ├── to_ingest/           # Landing zone for new replays → run ingest_replays.py
│   ├── scraped_overflow/    # (unused — all replays now ingested fully)
│   ├── plots/               # PNGs from analysis/experiments
│   └── experiments/         # Old experiment result JSONs
```

## Conventions
- **Modern era only (2025+)** — all training, analysis, and queries default to game_date >= 2025-01-01 unless explicitly noted otherwise
- Python venv at `.venv/` — use `.venv/bin/python` to run scripts
- Replay parser: `~/go/bin/screp` (Go binary, use with `-cmds` for commands, `-map` for positions)
- Database: `data/replays.db` (SQLite)
- New replays go to `data/to_ingest/`, get moved to `data/replays/` after ingestion
- With `class_weight="balanced"`, all available replays are used — no need to cap or overflow

## Data Labeling Rules
- This is data for training a classification model. It must be **HIGH FIDELITY**. Never label without 100% confidence that the mapping is correct.
- **NEVER add player_identities without explicit user confirmation.** Only add the exact aurora_id→canonical_name mappings the user tells you.
- Don't guess or infer identity from similar names in the database.

## Scraping Rules
- Scrape all available replays for labeled players — more data is better with `class_weight="balanced"`.
- For initial exploration of an unlabeled player, `--limit 50` is fine.

## Database Schema (data/replays.db)
- **replays** — one row per replay file: `id, file_hash, file_path, file_name, source_dir, map_name, game_date, duration_seconds, frames, version, created_at, winner_team, match_id`
- **players** — one row per player per replay: `id, replay_id, slot_id, player_name, race, is_human, start_x, start_y, start_direction, aurora_id`
- **player_identities** — maps aurora_ids to canonical pro names (training/predict source of truth): `id, canonical_name, aurora_id (UNIQUE), source, notes, created_at`
- **player_aliases** — legacy display-name reference (NOT used for training/predict): `id, canonical_name, alias, confidence, source, aurora_id`

## Current Model
- **Random Forest**: depth=10, trees=200, StandardScaler, LOO cross-validation
- **Modern era only**: Trains on replays with game_date >= 2025-01-01
- **99.1% accuracy** on 16 modern pros (stale — retrain pending with new players + code changes)
- Model saved to `data/model.joblib`, predictions to `data/predictions.json`
- Race-neutral features: abstract race-specific actions into generic categories (Train/Unit Morph → Prod)
- Consecutive Prod collapse to reduce race-mechanical signal

## Training & Prediction Thresholds
- **Training**: Auto-discovers all labeled players (in `player_identities`) with 10+ valid modern-era games via aurora_id join. No per-player cap — uses `class_weight="balanced"` to handle class imbalance. Alt accounts auto-merge (same aurora_id → same identity).
- **Prediction**: Runs on all unlabeled players with 10+ modern-era games. Groups by aurora_id where available, falls back to player_name grouping for players without aurora_id.
- **Filtering**: Single gate in `features.py` — games must be ≥ `MIN_GAME_MINUTES` (4) and ≥ `MIN_COMMANDS` (100)

## Data Pipeline
1. **Scrape** (`cwal.py scrape <alias>`) — downloads `.rep` files to `data/to_ingest/`, writes `_metadata.jsonl` with aurora_ids for both players per match
2. **Ingest** (`python ingest_replays.py`) — parses replays with screp, stores in DB, reads `_metadata.jsonl` to attach aurora_ids to the `players` table, extracts match_id from filename, moves files to `data/replays/`, deletes metadata file after
3. **Identity** — `player_identities` maps aurora_ids to canonical pro names. Training/predict join on `players.aurora_id → player_identities.aurora_id`. One canonical name can have multiple aurora_ids (alt accounts auto-merge).
4. Replays do NOT store aurora_ids — only display names. Aurora_ids come from cwal.gg API and are carried through via `_metadata.jsonl`.
5. **Backfill** (`python backfill_aurora_ids.py`) — one-time migration or periodic refresh. Tier 1 (offline): backfills match_id + aurora_ids by name. Tier 2 (`--api`): fetches opponent aurora_ids from cwal.gg.

## Workflow: Adding a New Player
1. Find their cwal.gg alias: `cwal.py search <name>`
2. Check game count: `cwal.py count <alias>`
3. Scrape replays: `cwal.py scrape <alias>` (scrapes all, writes metadata)
4. Ingest: `python ingest_replays.py` (reads metadata, stores aurora_ids)
5. Look up aurora_id: `cwal.py handles <alias>` or check `players` table
6. Add identity to DB (only with user confirmation): `INSERT INTO player_identities (canonical_name, aurora_id, source, created_at) VALUES (?, ?, 'manual', datetime('now'))`
7. Retrain: `python train.py`
8. Update experiments.md with results

## Blind Validation Queue
These are account-confirmed identities (via aurora_id) NOT yet in player_identities. Re-predict and check accuracy before adding.
- `llIIll1ll1lI` = Jaedong (aurora_id 13968871, gateway 11) — NOTE: Jaedong already has aurora_id 13968871 via jd2321232 alias; this is the SAME aurora_id so already merged
- `C9_HyuK9` = likely HyuK (same C9 tag, Zerg, but different account from C9_PSM — confirm via aurora_id or prediction)
- `wkelkqwlewqe` = sSak — RESOLVED: aurora_id 18372656 auto-merges with JSA_sSak1 (183 games total)

## cwal.gg API Notes
- Duration in `player_matches` is in **seconds** (decimal, e.g. 417.396 = 6:57)
- `map_name` field contains BW color codes (control chars) — use `map_file_name` instead
- `battlenet_account` field is on the `players` table, NOT on `rankings_view`
- Default gateway 30 = Korea, 10 = US West, 20 = US East, 45 = Europe
